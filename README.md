---
title: Fake News Detection MLOs Web App
emoji: ğŸ“ˆ
colorFrom: blue
colorTo: blue
sdk: docker
pinned: false
short_description: An end to end web app that allows to check for fake news
license: mit
---
# ğŸ“° Fake News Detector

A full-stack AI-powered fake news detection system built using Python, FastAPI, Streamlit, and traditional ML. This project demonstrates end-to-end skills in AI, machine learning, MLOps, and cloud deployment. It includes real-time inference, automatic retraining based on new data, drift detection, live monitoring, and user interactivityâ€”all hosted for free on HuggingFace Spaces.

ğŸ”— Live App: https://huggingface.co/spaces/Ahmedik95316/Fake-News-Detection-MLOs-Web-App

---

## ğŸš€ Overview: What This Project Demonstrates

This system showcases:

* âœ… Real-world problem framing and supervised learning pipeline
* âœ… Logistic Regression + TF-IDF for binary text classification (Fake vs Real news)
* âœ… FastAPI as a backend service for live model inference
* âœ… Streamlit frontend with confidence feedback and visualization
* âœ… Hourly scraping of real articles from news websites
* âœ… Generation of fake news headlines using prompt-style templates
* âœ… Automated retraining when new data is added
* âœ… Promotion strategy for candidate model vs production
* âœ… Jensen-Shannon divergence for detecting data drift
* âœ… JSON-based metadata and model versioning
* âœ… Activity and monitoring logs for training, drift, and promotion
* âœ… Custom CSV upload and live training inside the UI
* âœ… Entirely deployed and hosted on Render.com â€” no setup required for end users

This project proves your ability to bridge machine learning, DevOps, and user experience designâ€”all critical MLOps competencies.

---

## ğŸ§  What the System Does

This project automatically:

1. Scrapes real news articles every hour from **Reuters**, **BBC**, and **NPR**
2. Generates fake news headlines using programmatic templates
3. Appends new data to the dataset
4. Triggers retraining if data is added
5. Compares model accuracy to existing model
6. Promotes candidate model if it performs better
7. Logs drift scores and training events
8. Allows users to manually upload datasets and monitor training
9. Predicts Fake or Real for any given text through the Streamlit interface

---

## ğŸ“‚ Directory Breakdown

### `/app/`

* `fastapi_server.py` â€“ FastAPI backend serving the `/predict` endpoint. Used by Streamlit to perform live model inference.
* `streamlit_app.py` â€“ The main UI for users. Handles input, prediction, training visualization, metadata, drift monitoring, and upload support.

### `/data/`

* `prepare_datasets.py` â€“ Merges Kaggle and LIAR datasets, standardizes formats, and outputs a unified training file.
* `scrape_real_news.py` â€“ Scrapes the latest articles from Reuters, BBC, and NPR using newspaper3k.
* `generate_fake_news.py` â€“ Uses predefined templates to generate believable fake headlines and articles.
* `combined_dataset.csv` â€“ The master dataset combining real and fake news.
* `scraped_real.csv` â€“ Output from the scraper.
* `generated_fake.csv` â€“ Output from the fake news generator.

### `/model/`

* `train.py` â€“ Trains the ML model (Logistic Regression + TF-IDF) on the dataset provided.
* `retrain.py` â€“ Trains a candidate model on newly added data, compares it to the production model, and promotes it if accuracy improves.
* `model.pkl` â€“ Current production model.
* `vectorizer.pkl` â€“ TF-IDF encoder used with the production model.
* `model_candidate.pkl` â€“ Temporarily trained candidate model.
* `vectorizer_candidate.pkl` â€“ TF-IDF encoder for candidate model.
* `metadata.json` â€“ Tracks model version, training accuracy, and timestamp of last promotion.

### `/monitor/`

* `monitor_drift.py` â€“ Calculates Jensen-Shannon divergence between real-time data and training data to identify distributional shift.

### `/scheduler/`

* `schedule_tasks.py` â€“ Central scheduler that triggers scraping, fake generation, retraining, drift monitoring, and logging every hour.

### `/logs/`

* `activity_log.json` â€“ Timestamped logs of scraping, generation, and retraining activities.
* `monitoring_log.json` â€“ Drift scores and evaluation logs of candidate vs production model.

### Root Files

* `requirements.txt` â€“ All project dependencies
* `render.yaml` â€“ Configuration file used to deploy both backend and frontend on Render.com
* `README.md` â€“ The file you're reading

---

## ğŸ’¡ Automation Logic

Every hour (or every minute in test mode), the system:

1. Scrapes 15 new real news articles
2. Generates 20 new fake news articles
3. Appends them to the existing dataset
4. Triggers retraining of a candidate model
5. Compares it to the existing production model
6. If better, promotes the candidate to production
7. Logs drift score using Jensen-Shannon divergence
8. Updates visual logs and accuracy charts in the UI

---

ğŸŒ Live Deployment: Hugging Face Spaces
This project is fully deployed on Hugging Face Spaces using a Dockerized setup that includes both the Streamlit UI and FastAPI backend in a single container.

ğŸ”— Launch the App on Hugging Face Spaces
The app runs entirely within a Hugging Face-hosted Docker container.

Both the FastAPI inference server and Streamlit web interface are packaged together, ensuring fast internal communication.

The API_URL in streamlit_app.py is set to http://localhost:8000/predict to support intra-container requests.

The container uses Python 3.11.6, aligned with the local development environment for consistency and reproducibility.

âš™ï¸ Deployment Infrastructure
The deployment uses a custom Dockerfile tailored to match the exact development environment.

All dependencies are pinned to specific versions in the requirements.txt file to avoid incompatibilities.

The container runs both services concurrently using a process supervisor (if needed), ensuring a single deployment handles the complete user workflow.

---

## ğŸ¯ Skills Demonstrated

* AI/ML: Logistic Regression, TF-IDF, binary text classification
* MLOps: scheduled retraining, model promotion, version tracking
* Drift Detection: Jensen-Shannon divergence implementation
* Cloud DevOps: deploying two services via `render.yaml`
* UI/UX: live model prediction, upload, progress bars, logging
* Data Engineering: merging datasets, web scraping, labeling

---

## ğŸ§  Credits

* [LIAR Dataset (Politifact)](https://www.cs.ucsb.edu/~william/data/liar_dataset.zip)
* [Fake and Real News Dataset (Kaggle)](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)
* [newspaper3k](https://github.com/codelucas/newspaper)
* FastAPI, Streamlit, scikit-learn, Render

---

## ğŸ“œ License

MIT